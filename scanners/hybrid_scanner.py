"""
–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–∫–∞–Ω–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
"""
import os
import torch
import torch.nn.functional as F
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))

from .combined_scanner import ComplexFlagScanner
try:
    from neural_network.model_keypoints import create_keypoint_model
    from neural_network.data_loader_keypoints import FlagPatternKeypointDataset
    NN_AVAILABLE = True
except ImportError:
    NN_AVAILABLE = False
    print("‚ö†Ô∏è  –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–º–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã)")


class HybridFlagScanner(ComplexFlagScanner):
    """
    –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–∫–∞–Ω–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π:
    - –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    - –ù–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    """
    
    def __init__(self, token: str, model_path: str = None, device: str = 'cpu', 
                 nn_window: int = 100, nn_min_confidence: float = 0.5, use_nn: bool = True):
        """
        Args:
            token: Tinkoff Invest API —Ç–æ–∫–µ–Ω
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π ('cpu' –∏–ª–∏ 'cuda')
            nn_window: –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            nn_min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            use_nn: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å (–µ—Å–ª–∏ False, —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫–∞–Ω–µ—Ä)
        """
        super().__init__(token)
        self.use_nn = use_nn
        self.nn_window = nn_window
        self.nn_min_confidence = nn_min_confidence
        self.device = torch.device(device)
        
        if self.use_nn:
            if not NN_AVAILABLE:
                print("‚ö†Ô∏è  –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
                self.use_nn = False
                self.nn_model = None
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
                if model_path is None:
                    model_path = 'neural_network/models/keypoint_model_best.pth'
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
                    if not os.path.exists(model_path):
                        model_path = str(Path(__file__).parent.parent / model_path)
                
                if os.path.exists(model_path):
                    print(f"üèóÔ∏è  –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
                    self.nn_model = create_keypoint_model(
                        num_classes=3,
                        num_keypoints=5,
                        image_height=224,
                        image_width=224,
                        pretrained_path=model_path
                    )
                    self.nn_model.to(self.device)
                    self.nn_model.eval()
                    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device})")
                else:
                    print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}, –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∞")
                    self.use_nn = False
                    self.nn_model = None
        else:
            self.nn_model = None
    
    def _evaluate_pattern_with_nn(self, df, pattern_info, window_start: int = 0):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞–π–¥–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–∫–∞–Ω–µ—Ä–æ–º —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
        
        Args:
            df: DataFrame —Å–æ —Å–≤–µ—á–∞–º–∏
            pattern_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ç—Ç–µ—Ä–Ω–µ –æ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–µ—Ä–∞
            window_start: –ù–∞—á–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –æ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            dict: {
                'nn_confidence': float,  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (0-1)
                'nn_class': int,         # –ö–ª–∞—Å—Å –æ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (1=–±—ã—á–∏–π, 2=–º–µ–¥–≤–µ–∂–∏–π)
                'nn_match': bool         # –°–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –∫–ª–∞—Å—Å —Å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–∫–∞–Ω–µ—Ä–æ–º
            }
        """
        if not self.use_nn or self.nn_model is None:
            return {
                'nn_confidence': 0.0,
                'nn_class': 0,
                'nn_match': False
            }
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã —Ç–æ—á–µ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
            t0_idx = pattern_info.get('t0', {}).get('idx', 0)
            t4_idx = pattern_info.get('t4', {}).get('idx', 0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∫–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–µ)
            pattern_center = (t0_idx + t4_idx) // 2
            window_half = self.nn_window // 2
            
            start_idx = max(0, pattern_center - window_half)
            end_idx = min(len(df), start_idx + self.nn_window)
            
            # –ï—Å–ª–∏ –æ–∫–Ω–æ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã, —Å–¥–≤–∏–≥–∞–µ–º
            if end_idx - start_idx < self.nn_window:
                end_idx = min(len(df), start_idx + self.nn_window)
                start_idx = max(0, end_idx - self.nn_window)
            
            df_window = df.iloc[start_idx:end_idx].copy().reset_index(drop=True)
            
            if len(df_window) < 50:  # –ú–∏–Ω–∏–º—É–º —Å–≤–µ—á–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                return {
                    'nn_confidence': 0.0,
                    'nn_class': 0,
                    'nn_match': False
                }
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            dataset = FlagPatternKeypointDataset("", image_size=(224, 224), window=len(df_window))
            image_tensor, _ = dataset._candles_to_image(df_window, window=len(df_window))
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            with torch.no_grad():
                image_batch = image_tensor.unsqueeze(0).to(self.device)
                class_logits, _ = self.nn_model(image_batch)
                probabilities = F.softmax(class_logits, dim=1)
                predicted_class = torch.argmax(class_logits, dim=1).item()
                pred_prob = probabilities[0][predicted_class].item()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –æ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–µ—Ä–∞
            pattern_name = pattern_info.get('pattern', '')
            math_class = 1 if 'BEARISH' not in pattern_name and 'FLAG' in pattern_name else 2 if 'BEARISH' in pattern_name else 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
            nn_match = (predicted_class == math_class) and (predicted_class > 0)
            
            return {
                'nn_confidence': pred_prob,
                'nn_class': predicted_class,
                'nn_match': nn_match
            }
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é: {e}")
            return {
                'nn_confidence': 0.0,
                'nn_class': 0,
                'nn_match': False
            }
    
    def analyze(self, df, debug=False, timeframe='1h', 
                filter_by_nn: bool = True, min_nn_confidence: float = None):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–ø–æ–ª—å–∑—É—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫–∞–Ω–µ—Ä –∏ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
        
        Args:
            df: DataFrame —Å–æ —Å–≤–µ—á–∞–º–∏
            debug: –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏
            timeframe: –¢–∞–π–º—Ñ—Ä–µ–π–º
            filter_by_nn: –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            min_nn_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.nn_min_confidence)
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∫–∞–Ω–µ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        math_patterns = super().analyze(df, debug=debug, timeframe=timeframe)
        
        if not math_patterns:
            return []
        
        if not self.use_nn:
            # –ï—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–µ—Ä–∞
            for pattern in math_patterns:
                pattern['nn_confidence'] = 0.0
                pattern['nn_class'] = 0
                pattern['nn_match'] = False
            return math_patterns
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é
        min_confidence = min_nn_confidence if min_nn_confidence is not None else self.nn_min_confidence
        evaluated_patterns = []
        
        for pattern in math_patterns:
            nn_result = self._evaluate_pattern_with_nn(df, pattern)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            pattern['nn_confidence'] = nn_result['nn_confidence']
            pattern['nn_class'] = nn_result['nn_class']
            pattern['nn_match'] = nn_result['nn_match']
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∫–ª–∞—Å—Å–æ–≤
            if filter_by_nn:
                if nn_result['nn_confidence'] >= min_confidence and nn_result['nn_match']:
                    evaluated_patterns.append(pattern)
            else:
                # –ù–µ —Ñ–∏–ª—å—Ç—Ä—É–µ–º, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                evaluated_patterns.append(pattern)
        
        return evaluated_patterns
    
    def analyze_with_nn_only(self, df, window: int = None, step: int = None, min_confidence: float = None):
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å (sliding window)
        
        Args:
            df: DataFrame —Å–æ —Å–≤–µ—á–∞–º–∏
            window: –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.nn_window)
            step: –®–∞–≥ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è window // 10)
            min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è self.nn_min_confidence)
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é
        """
        if not self.use_nn or self.nn_model is None:
            return []
        
        if not NN_AVAILABLE:
            return []
        
        from neural_network.predict_keypoints import predict_with_sliding_window
        
        window_size = window or self.nn_window
        step_size = step or max(10, window_size // 10)
        min_conf = min_confidence or self.nn_min_confidence
        
        predictions = predict_with_sliding_window(
            df, 
            self.nn_model, 
            window=window_size, 
            step=step_size, 
            device=self.device, 
            min_confidence=min_conf
        )
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–µ—Ä–∞
        patterns = []
        for pred in predictions:
            points = pred['points']
            if len(points) == 5:
                pattern = {
                    'pattern': 'BULLISH_FLAG' if pred['class'] == 1 else 'BEARISH_FLAG',
                    't0': {'idx': points[0]['idx'], 'price': points[0]['price']},
                    't1': {'idx': points[1]['idx'], 'price': points[1]['price']},
                    't2': {'idx': points[2]['idx'], 'price': points[2]['price']},
                    't3': {'idx': points[3]['idx'], 'price': points[3]['price']},
                    't4': {'idx': points[4]['idx'], 'price': points[4]['price']},
                    'nn_confidence': pred['probability'],
                    'nn_class': pred['class'],
                    'nn_match': True,  # –í—Å–µ–≥–¥–∞ True –¥–ª—è NN-only
                    'source': 'neural_network'
                }
                patterns.append(pattern)
        
        return patterns

