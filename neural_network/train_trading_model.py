import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
# import matplotlib.pyplot as plt
# import seaborn as sns

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DATASET_FILE = Path("neural_network/data/ml_trading_dataset.csv")
MODEL_FILE = Path("neural_network/models/trading_model_rf.pkl")
MODEL_FILE.parent.mkdir(parents=True, exist_ok=True)

def train_model():
    print("üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Å–¥–µ–ª–æ–∫...")
    
    if not DATASET_FILE.exists():
        print(f"‚ùå –§–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {DATASET_FILE}")
        return

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = pd.read_csv(DATASET_FILE)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Features)
    # –ù–∞–º –Ω—É–∂–Ω–æ –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —á–∏—Å–ª–∞, –ø–æ–Ω—è—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: 1 = WIN, 0 = LOSS/HOLD
    # HOLD —Å—á–∏—Ç–∞–µ–º –∑–∞ LOSS –¥–ª—è —Å—Ç—Ä–æ–≥–æ—Å—Ç–∏ (–Ω–µ –¥–æ—à–ª–∏ –¥–æ —Ü–µ–ª–∏)
    df['target'] = (df['outcome'] == 'WIN').astype(int)
    
    # –§–∏—á–∏
    # correction_ratio: –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –∫ –¥—Ä–µ–≤–∫—É (0.3-0.5 –æ–±—ã—á–Ω–æ —Ö–æ—Ä–æ—à–æ)
    # slope_channel: –ù–∞–∫–ª–æ–Ω –∫–∞–Ω–∞–ª–∞
    
    # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ñ–∏—á–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    # –ù–∞–ø—Ä–∏–º–µ—Ä, Risk/Reward ratio (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π)
    df['risk_reward_ratio'] = abs(df['take_profit'] - df['entry_price']) / abs(df['entry_price'] - df['stop_loss'])
    
    # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    feature_cols = [
        'correction_ratio', 
        'slope_channel', 
        'risk_reward_ratio'
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –∏ —á–∏—Å—Ç–∏–º
    df_clean = df.dropna(subset=feature_cols + ['target'])
    
    X = df_clean[feature_cols]
    y = df_clean['target']
    
    print(f"   –î–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(X)}")
    print(f"   –ë–∞–∑–æ–≤—ã–π Win Rate: {y.mean()*100:.1f}%")
    
    # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ Train/Test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (Random Forest)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º class_weight='balanced', —á—Ç–æ–±—ã —É—á–µ—Å—Ç—å –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ (–µ—Å–ª–∏ Win Rate –Ω–∏–∑–∫–∏–π)
    clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight='balanced')
    clf.fit(X_train, y_train)
    
    # 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    y_pred = clf.predict(X_test)
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    print(classification_report(y_test, y_pred))
    
    acc = accuracy_score(y_test, y_pred)
    print(f"   Accuracy: {acc:.2f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "–±–æ–µ–≤—ã—Ö" –ø—Ä–∏–º–µ—Ä–∞—Ö
    # –î–æ–ø—É—Å—Ç–∏–º, –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ 1 (WIN). –ö–∞–∫–æ–≤–∞ —Ä–µ–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ç–∞–∫–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤?
    # –≠—Ç–æ Precision –¥–ª—è –∫–ª–∞—Å—Å–∞ 1.
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    precision_win = tp / (tp + fp) if (tp + fp) > 0 else 0
    
    print(f"\nüéØ –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ WIN (Precision): {precision_win*100:.1f}%")
    print("   (–≠—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Å–¥–µ–ª–∫–∏, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —Å–∫–∞–∑–∞–ª–∞ '–í–•–û–î–ò')")
    
    # 6. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    importances = clf.feature_importances_
    feature_imp = pd.DataFrame(sorted(zip(importances, feature_cols)), columns=['Value','Feature'])
    
    print("\nüîë –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    print(feature_imp.sort_values(by="Value", ascending=False).to_string(index=False))
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    joblib.dump(clf, MODEL_FILE)
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_FILE}")
    
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("\nüí° –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞:")
    # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ —Ç–µ—Å—Ç–∞
    sample = X_test.iloc[0:1]
    prediction = clf.predict(sample)[0]
    proba = clf.predict_proba(sample)[0][1]
    
    print(f"   –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {sample.to_dict(orient='records')[0]}")
    print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {'WIN' if prediction==1 else 'SKIP'} (–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {proba:.2f})")

if __name__ == "__main__":
    train_model()
