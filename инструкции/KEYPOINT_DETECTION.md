# Детекция ключевых точек для паттернов "Флаг"

## Текущее состояние

**Что делает нейросеть сейчас:**
- ✅ Классифицирует паттерны (0=нет паттерна, 1=бычий, 2=медвежий)
- ❌ Не предсказывает координаты точек T0-T4
- ❌ Не может отрисовать паттерн самостоятельно

**Почему так:**
- Текущая модель `FlagPatternCNN` обучается для задачи **классификации**
- Выход модели: 3 значения (вероятности классов)
- Нет информации о позициях точек на графике

## Что нужно для самостоятельной отрисовки

Чтобы нейросеть могла отрисовывать паттерны самостоятельно, нужно:

1. **Изменить архитектуру модели** - добавить выход для предсказания координат
2. **Изменить данные для обучения** - хранить координаты точек T0-T4
3. **Изменить функцию потерь** - использовать loss для регрессии координат
4. **Переобучить модель** на новых данных

## Варианты реализации

### Вариант 1: Мультизадачная модель (Classification + Regression)

Модель предсказывает:
- **Класс паттерна** (классификация)
- **Координаты точек T0-T4** (регрессия)

**Архитектура:**
```
Вход: изображение (224x224x3)
  ↓
[CNN backbone - общие признаки]
  ↓
      ├─→ [Классификация] → 3 класса (бычий/медвежий/нет)
      └─→ [Регрессия] → 10 значений (x, y для 5 точек: T0, T1, T2, T3, T4)
```

**Преимущества:**
- Одна модель для классификации и детекции точек
- Меньше вычислений

**Недостатки:**
- Сложнее обучать (два loss)
- Нужно больше данных

### Вариант 2: Отдельная модель для keypoint detection

Отдельная модель, которая:
- Принимает на вход область с паттерном
- Предсказывает координаты точек T0-T4

**Архитектура:**
- Можно использовать готовые архитектуры для keypoint detection:
  - Hourglass Network
  - Stacked Hourglass
  - Simple Baselines for Human Pose Estimation
  - HRNet

**Преимущества:**
- Специализированная модель
- Можно использовать pre-trained модели

**Недостатки:**
- Нужно две модели (классификация + детекция)
- Больше параметров

### Вариант 3: Object Detection подход (YOLO/RetinaNet)

Модель, которая:
- Находит паттерн на графике (bounding box)
- Предсказывает координаты точек T0-T4 внутри bounding box

**Преимущества:**
- Может находить несколько паттернов на графике
- Не нужен предварительный поиск области

**Недостатки:**
- Более сложная архитектура
- Требуется много размеченных данных

## Рекомендация: Вариант 1 (Мультизадачная модель)

Для задачи паттерна "Флаг" лучше всего подходит **мультизадачная модель**:

1. ✅ У вас уже есть размеченные данные с координатами T0-T4
2. ✅ Паттерн имеет фиксированную структуру (всегда 5 точек)
3. ✅ Можно использовать существующую CNN архитектуру

## Что нужно для реализации

### 1. Изменить формат данных

Текущий формат аннотаций (annotations.csv):
```csv
file_name,label,t0_idx,t0_price,t1_idx,t1_price,...
```

**Нужно хранить координаты в пикселях изображения:**
```csv
file_name,label,t0_x,t0_y,t1_x,t1_y,t2_x,t2_y,t3_x,t3_y,t4_x,t4_y
```

Или хранить относительные координаты (0-1):
```csv
file_name,label,t0_x_norm,t0_y_norm,t1_x_norm,t1_y_norm,...
```

### 2. Изменить модель

Добавить к текущей `FlagPatternCNN` выход для регрессии:

```python
class FlagPatternCNNWithKeypoints(nn.Module):
    def __init__(self, num_classes=3, num_keypoints=5):
        # ... существующие слои CNN ...
        
        # Классификация
        self.fc_class = nn.Linear(256, num_classes)
        
        # Регрессия координат (x, y для каждой точки)
        self.fc_keypoints = nn.Linear(256, num_keypoints * 2)  # 10 значений
    
    def forward(self, x):
        # ... CNN backbone ...
        
        # Классификация
        class_logits = self.fc_class(features)
        
        # Координаты точек
        keypoints = self.fc_keypoints(features)  # [batch, 10]
        keypoints = keypoints.view(-1, 5, 2)  # [batch, 5 точек, 2 координаты]
        
        return class_logits, keypoints
```

### 3. Изменить функцию потерь

Комбинированный loss:
```python
# Loss для классификации
classification_loss = CrossEntropyLoss()(class_logits, labels)

# Loss для регрессии координат (только для примеров с паттерном)
keypoint_loss = MSELoss()(keypoints, target_keypoints)

# Комбинированный loss
total_loss = classification_loss + lambda * keypoint_loss
```

### 4. Обновить data loader

Загружать координаты точек из аннотаций и преобразовывать в координаты изображения.

## Альтернативный подход (более простой)

Если не хотите переобучать модель, можно использовать **гибридный подход**:

1. Нейросеть находит области с паттернами (классификация)
2. В этих областях запускается математический сканер для определения точек
3. Отрисовываются найденные паттерны

**Это уже реализовано в `test_nn_patterns.py`!** ✅

## Вопросы для принятия решения

1. **Нужна ли 100% точность координат?**
   - Если да → дообучать модель для keypoint detection
   - Если нет → гибридный подход (НС + математический сканер)

2. **Сколько размеченных данных есть?**
   - Для keypoint detection нужно больше данных (500-1000+ примеров)
   - Для гибридного подхода достаточно текущих данных

3. **Нужна ли скорость?**
   - Keypoint detection быстрее (одна модель)
   - Гибридный подход медленнее (два этапа)

## Вывод

**Текущий подход (гибридный):**
- ✅ Уже работает
- ✅ Не требует переобучения
- ✅ Использует сильные стороны обоих методов
- ❌ Два этапа (медленнее)
- ❌ Зависит от математического сканера

**Keypoint Detection:**
- ✅ Один этап (быстрее)
- ✅ Независим от математического сканера
- ✅ Может найти паттерны, которые не находит сканер
- ❌ Требует переобучения
- ❌ Нужно больше данных
- ❌ Сложнее реализация

