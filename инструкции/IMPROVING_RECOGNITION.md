# Как улучшить качество распознавания паттернов

## Проблема: паттерны не найдены

Если модель не находит паттерны, это может быть по нескольким причинам:

### 1. Слишком высокий порог уверенности (min_confidence)

**Текущее значение:** 0.7 (70%)

**Решение:** Снизить порог для тестирования:

```bash
python3 neural_network/predict_keypoints.py \
  --ticker MXH6 \
  --timeframe 1h \
  --from_date 2025-10-20 \
  --min_confidence 0.5  # Снизить до 50%
```

Или даже до 0.3 (30%) для начала:

```bash
--min_confidence 0.3
```

**Рекомендация:** 
- Начать с 0.3-0.4 для исследования
- Если найдены паттерны, постепенно повышать до 0.6-0.7

---

### 2. Недостаточно обучающих данных

**Текущее количество:** 72 примера

**Рекомендации:**
- ✅ **Минимум:** 100-150 примеров для базового качества
- ✅ **Хорошо:** 200-300 примеров
- ✅ **Отлично:** 500+ примеров

**Что делать:**
1. Разметьте больше паттернов через `labeling_dashboard.py`
2. Используйте разнообразные инструменты и таймфреймы
3. Включайте как качественные, так и пограничные примеры

---

### 3. Улучшить обучение модели

#### A. Увеличить количество эпох

Текущее: 50 эпох

```bash
python3 neural_network/train_keypoints.py \
  --epochs 100 \
  --batch_size 8 \
  --learning_rate 0.0005  # Снизить learning rate при большем количестве эпох
```

#### B. Настройка весов loss

```bash
python3 neural_network/train_keypoints.py \
  --classification_weight 1.0 \
  --keypoint_weight 2.0  # Увеличить вес keypoints (более важно точное расположение точек)
```

#### C. Использовать data augmentation

Добавить аугментацию данных (повороты, масштабирование, изменение яркости) для увеличения разнообразия обучающих данных.

---

### 4. Проверить качество обучающих данных

#### Проверка распределения классов:

```python
import pandas as pd
df = pd.read_csv('neural_network/data/annotations.csv')
print(df['label'].value_counts())
```

**Рекомендация:** 
- Баланс классов: примерно равное количество бычьих и медвежьих паттернов
- Если дисбаланс: добавить больше примеров редкого класса

#### Проверка качества разметки:

- Убедитесь, что все точки T0-T4 правильно размечены
- Проверьте, что координаты соответствуют реальным точкам на графике
- Используйте `labeling_dashboard.py` для просмотра и исправления

---

### 5. Настройка параметров анализа

#### A. Изменить размер окна

Текущее: 100 свечей

```bash
python3 neural_network/predict_keypoints.py \
  --window 150  # Увеличить для более широкого контекста
```

Или уменьшить:

```bash
--window 80  # Для более локального анализа
```

#### B. Изменить шаг sliding window

Текущее: 10 свечей (автоматически = window // 10)

```bash
python3 neural_network/predict_keypoints.py \
  --step 5  # Более детальный анализ (больше окон, медленнее)
```

Или:

```bash
--step 20  # Быстрее, но может пропустить паттерны
```

---

### 6. Использовать ансамбль моделей

Обучить несколько моделей с разными параметрами и объединить предсказания:

```python
# Псевдокод
models = [
    load_model('model_best_1.pth'),
    load_model('model_best_2.pth'),
    load_model('model_best_3.pth')
]

predictions = [model.predict(data) for model in models]
final_prediction = aggregate(predictions)  # Среднее или голосование
```

---

### 7. Анализ проблемных случаев

#### Проверить, что модель видит:

```python
# Визуализировать предсказания даже с низкой уверенностью
python3 neural_network/predict_keypoints.py \
  --min_confidence 0.1  # Очень низкий порог для исследования
```

Если даже с 0.1 ничего не находится - проблема в модели или данных.

#### Проверить распределение предсказаний:

Добавить логирование всех предсказаний (не только с высокой уверенностью) для анализа.

---

## План действий (приоритет)

### Быстрое улучшение (можно сделать сразу):

1. ✅ **Снизить min_confidence до 0.3-0.4** и протестировать
2. ✅ **Разметить больше данных** (до 150-200 примеров)
3. ✅ **Переобучить модель** на расширенном датасете (100 эпох)

### Среднесрочные улучшения (1-2 дня):

4. ✅ Проверить баланс классов и добавить недостающие примеры
5. ✅ Настроить веса loss (keypoint_weight)
6. ✅ Поэкспериментировать с размером окна (80-150)

### Долгосрочные улучшения (неделя+):

7. ✅ Добавить data augmentation
8. ✅ Обучить ансамбль моделей
9. ✅ Использовать transfer learning (предобученные модели)

---

## Пример команды для тестирования с низким порогом:

```bash
cd complex_flag_scanner

# Тест с низким порогом уверенности
python3 neural_network/predict_keypoints.py \
  --ticker MXH6 \
  --class_code SPBFUT \
  --timeframe 1h \
  --from_date 2025-10-20 \
  --min_confidence 0.3 \
  --window 100 \
  --step 10
```

---

## Диагностика проблемы

Если паттерны не находятся даже с низким порогом (0.1-0.2):

1. **Проверьте обучение:**
   ```bash
   # Посмотрите на метрики обучения
   cat neural_network/models/training_history.json
   ```

2. **Проверьте валидацию:**
   - Val Accuracy должна быть > 80%
   - Val Loss должна уменьшаться

3. **Проверьте данные:**
   - Все ли примеры правильно размечены?
   - Нет ли ошибок в координатах?

4. **Проверьте распределение:**
   - Разнообразие инструментов
   - Разнообразие таймфреймов
   - Разнообразие условий рынка

---

## Контакты и помощь

Если проблема не решается:
- Проверьте логи обучения
- Убедитесь, что модель сохранилась правильно
- Попробуйте обучить модель заново с нуля

