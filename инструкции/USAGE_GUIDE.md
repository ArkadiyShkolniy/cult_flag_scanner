# –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –º–æ–¥—É–ª—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π)
2. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è](#–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–¥–∞–Ω–Ω—ã—Ö-–¥–ª—è-–æ–±—É—á–µ–Ω–∏—è)
3. [–†–∞–∑–º–µ—Ç–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤](#—Ä–∞–∑–º–µ—Ç–∫–∞-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
4. [–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏](#–æ–±—É—á–µ–Ω–∏–µ-–º–æ–¥–µ–ª–∏)
5. [–î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö](#–¥–æ–æ–±—É—á–µ–Ω–∏–µ-–Ω–∞-–Ω–æ–≤—ã—Ö-–¥–∞–Ω–Ω—ã—Ö)
6. [–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π](#–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ-–¥–ª—è-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)
7. [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ —Å–∫–∞–Ω–µ—Ä–æ–º](#–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è-—Å–æ-—Å–∫–∞–Ω–µ—Ä–æ–º)
8. [–ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã](#—á–∞—Å—Ç–æ-–∑–∞–¥–∞–≤–∞–µ–º—ã–µ-–≤–æ–ø—Ä–æ—Å—ã)

---

## 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

–ú–æ–¥—É–ª—å —Ç—Ä–µ–±—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:
- PyTorch (–¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π)
- torchvision (–¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)
- Pillow (–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
- tqdm (–¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–≤)

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
cd complex_flag_scanner

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install torch torchvision pillow tqdm

# –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
pip install -r requirements.txt
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

```python
import torch
print(f"PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
print(f"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")

# –ï—Å–ª–∏ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞, —ç—Ç–æ —É—Å–∫–æ—Ä–∏—Ç –æ–±—É—á–µ–Ω–∏–µ
if torch.cuda.is_available():
    print(f"CUDA —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {torch.cuda.get_device_name(0)}")
```

---

## 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π

–ú–æ–¥—É–ª—å —Å–æ–∑–¥–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:

```
complex_flag_scanner/
‚îî‚îÄ‚îÄ neural_network/
    ‚îú‚îÄ‚îÄ data/                    # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    ‚îÇ   ‚îú‚îÄ‚îÄ candles/            # CSV —Ñ–∞–π–ª—ã —Å–æ —Å–≤–µ—á–∞–º–∏
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vkco_1h_20240101_120000.csv
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sber_1h_20240101_130000.csv
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ annotations.csv      # –§–∞–π–ª —Å –º–µ—Ç–∫–∞–º–∏ (—Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
    ‚îî‚îÄ‚îÄ models/                  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        ‚îú‚îÄ‚îÄ best_model.pth      # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
        ‚îî‚îÄ‚îÄ last_model.pth      # –ü–æ—Å–ª–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å
```

### –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∞–Ω–Ω–æ—Ç–∞—Ç–æ—Ä–∞:

```python
from neural_network.annotator import PatternAnnotator

# –°–æ–∑–¥–∞—Å—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
annotator = PatternAnnotator()
```

---

## 3. –†–∞–∑–º–µ—Ç–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

### 3.1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∫–∞–Ω–µ—Ä–∞

–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–µ—Ä–∞:

```python
import os
from dotenv import load_dotenv
from scanners.combined_scanner import ComplexFlagScanner
from neural_network.annotator import PatternAnnotator

load_dotenv()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
token = os.environ.get('TINKOFF_INVEST_TOKEN')
scanner = ComplexFlagScanner(token)
annotator = PatternAnnotator()

# –°–∫–∞–Ω–∏—Ä—É–µ–º –∞–∫—Ü–∏—é
ticker = 'VKCO'
class_code = 'TQBR'
timeframe = '1h'

df = scanner.get_candles_df(ticker, class_code, days_back=60, interval=scanner.bullish_scanner.get_candles_df(ticker, class_code).interval)
patterns = scanner.analyze(df, timeframe=timeframe)

# –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
if patterns:
    pattern_info = patterns[0]
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞
    # –ú–µ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: 1=–±—ã—á–∏–π, 2=–º–µ–¥–≤–µ–∂–∏–π
    annotator.annotate_from_scanner(
        df=df,
        ticker=ticker,
        timeframe=timeframe,
        pattern_info=pattern_info
    )
    
    print(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω —Ä–∞–∑–º–µ—á–µ–Ω: {pattern_info['pattern']}")
```

### 3.2. –†—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞

–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –≤—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞—Ç—å –º–µ—Ç–∫—É:

```python
from neural_network.annotator import PatternAnnotator
import pandas as pd

annotator = PatternAnnotator()

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏
df = pd.read_csv('path/to/candles.csv')

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–µ—á–∏ –∏ –ø–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
candles_file = annotator.save_candles(
    df=df,
    ticker='VKCO',
    timeframe='1h'
)

# –†–∞–∑–º–µ—á–∞–µ–º –≤—Ä—É—á–Ω—É—é
# label: 0 = –Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞, 1 = –±—ã—á–∏–π, 2 = –º–µ–¥–≤–µ–∂–∏–π
annotator.annotate_pattern(
    candles_file=candles_file,
    label=1,  # –ë—ã—á–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
    ticker='VKCO',
    timeframe='1h',
    pattern_type='FLAG_0_1_2_3_4',
    notes='–•–æ—Ä–æ—à–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω'
)
```

### 3.3. –†–∞–∑–º–µ—Ç–∫–∞ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π

–í–∞–∂–Ω–æ –ø–æ–º–µ—á–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è —Å–∫–∞–Ω–µ—Ä–∞:

```python
# –ï—Å–ª–∏ —Å–∫–∞–Ω–µ—Ä –Ω–∞—à–µ–ª –ø–∞—Ç—Ç–µ—Ä–Ω, –Ω–æ –≤—ã –≤–∏–¥–∏—Ç–µ —á—Ç–æ –µ–≥–æ –Ω–µ—Ç
patterns = scanner.analyze(df, timeframe='1h')

if patterns:
    pattern_info = patterns[0]
    
    # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ª–æ–∂–Ω–æ–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ
    annotator.annotate_false_positive(
        df=df,
        ticker=ticker,
        timeframe=timeframe,
        scanner_result=pattern_info
    )
    
    print("‚ö†Ô∏è –ü–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –ª–æ–∂–Ω–æ–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ")
```

### 3.4. –ü–∞–∫–µ—Ç–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞

–î–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:

```python
import os
from scanners.combined_scanner import ComplexFlagScanner
from neural_network.annotator import PatternAnnotator

token = os.environ.get('TINKOFF_INVEST_TOKEN')
scanner = ComplexFlagScanner(token)
annotator = PatternAnnotator()

# –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
tickers = ['VKCO', 'SBER', 'GAZP', 'LKOH', 'YNDX']

for ticker in tickers:
    print(f"\n–°–∫–∞–Ω–∏—Ä—É—é {ticker}...")
    
    try:
        df = scanner.get_candles_df(ticker, 'TQBR', days_back=60)
        
        if not df.empty:
            patterns = scanner.analyze(df, timeframe='1h')
            
            if patterns:
                for pattern_info in patterns:
                    annotator.annotate_from_scanner(
                        df=df,
                        ticker=ticker,
                        timeframe='1h',
                        pattern_info=pattern_info
                    )
                    print(f"  ‚úÖ –†–∞–∑–º–µ—á–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: {pattern_info['pattern']}")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {ticker}: {e}")

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
annotator.print_statistics()
```

### 3.5. –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏

```python
from neural_network.annotator import PatternAnnotator

annotator = PatternAnnotator()

# –í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
annotator.print_statistics()

# –ò–ª–∏ –ø–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
stats = annotator.get_statistics()
print(f"–í—Å–µ–≥–æ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {stats['total']}")
print(f"–ü–æ –º–µ—Ç–∫–∞–º: {stats['by_label']}")
print(f"–ü–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º: {stats['by_timeframe']}")
```

---

## 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### 4.1. –ü–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```python
import torch
from neural_network.model import create_model
from neural_network.trainer import ModelTrainer
from neural_network.data_loader import create_data_loader

# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = create_model(num_classes=3)  # 0=–Ω–µ—Ç, 1=–±—ã—á–∏–π, 2=–º–µ–¥–≤–µ–∂–∏–π

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
train_loader, val_loader = create_data_loader(
    data_dir='neural_network/data',
    batch_size=16,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (—É–º–µ–Ω—å—à–∏—Ç–µ –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏)
    image_size=(224, 224),
    train_split=0.8  # 80% –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, 20% –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
)

print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(train_loader.dataset)}")
if val_loader:
    print(f"–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(val_loader.dataset)}")

# –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤—â–∏–∫
trainer = ModelTrainer(model, device=device)

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=50,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
    learning_rate=0.001,  # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    save_dir='neural_network/models',
    save_best=True,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    save_last=True   # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
)
```

### 4.2. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è (Resume)

–ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–ª–æ—Å—å, –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å:

```python
from neural_network.model import create_model
from neural_network.trainer import ModelTrainer
from neural_network.data_loader import create_data_loader

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
model = create_model(
    num_classes=3,
    pretrained_path='neural_network/models/last_model.pth'
)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
train_loader, val_loader = create_data_loader('neural_network/data')

# –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤—â–∏–∫
trainer = ModelTrainer(model)

# –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=50,
    learning_rate=0.0001,  # –ú–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
    save_dir='neural_network/models',
    resume_from='neural_network/models/last_model.pth'  # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å —ç—Ç–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
)
```

### 4.3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—Ä–∏—é:

```python
import json

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
with open('neural_network/models/training_history.json', 'r') as f:
    history = json.load(f)

# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history['epochs'], history['train_acc'], label='Train')
if history['val_acc']:
    plt.plot(history['epochs'], history['val_acc'], label='Val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.title('–¢–æ—á–Ω–æ—Å—Ç—å')

plt.subplot(1, 2, 2)
plt.plot(history['epochs'], history['train_loss'], label='Train')
if history['val_loss']:
    plt.plot(history['epochs'], history['val_loss'], label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('–ü–æ—Ç–µ—Ä–∏')

plt.tight_layout()
plt.savefig('training_history.png')
plt.show()
```

---

## 5. –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

–ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –≤—ã —Ä–∞–∑–º–µ—Ç–∏–ª–∏ –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å:

```python
from neural_network.model import create_model
from neural_network.trainer import ModelTrainer
from neural_network.data_loader import create_data_loader

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
model = create_model(
    num_classes=3,
    pretrained_path='neural_network/models/best_model.pth'
)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–ª–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–Ω–æ–≤–æ)
new_data_loader, _ = create_data_loader(
    data_dir='neural_network/data',
    batch_size=16,
    train_split=1.0  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
)

# –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤—â–∏–∫
trainer = ModelTrainer(model)

# –î–æ–æ–±—É—á–∞–µ–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π learning rate)
trainer.fine_tune(
    new_data_loader=new_data_loader,
    epochs=5,  # –ú–µ–Ω—å—à–µ —ç–ø–æ—Ö –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
    learning_rate=0.0001  # –ú–µ–Ω—å—à–∏–π learning rate
)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
trainer.save_checkpoint(
    'neural_network/models/finetuned_model.pth',
    epoch=0,
    best_val_acc=0
)
```

---

## 6. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

### 6.1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –æ–±—Ä–∞–∑—Ü–µ

```python
import torch
from neural_network.model import create_model
from neural_network.data_loader import FlagPatternDataset

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = create_model(
    num_classes=3,
    pretrained_path='neural_network/models/best_model.pth'
)
model.eval()  # –†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
dataset = FlagPatternDataset('neural_network/data')
image, true_label = dataset[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –æ–±—Ä–∞–∑–µ—Ü

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–¥–æ–±–∞–≤–ª—è–µ–º batch dimension)
image_batch = image.unsqueeze(0)  # (1, 3, 224, 224)

pred_class, probabilities = model.predict(image_batch)

print(f"–ò—Å—Ç–∏–Ω–Ω–∞—è –º–µ—Ç–∫–∞: {true_label}")
print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {pred_class.item()}")
print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {probabilities[0]}")
print(f"  - –ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {probabilities[0][0]:.2%}")
print(f"  - –ë—ã—á–∏–π: {probabilities[0][1]:.2%}")
print(f"  - –ú–µ–¥–≤–µ–∂–∏–π: {probabilities[0][2]:.2%}")
```

### 6.2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–µ

```python
from neural_network.model import create_model
from neural_network.trainer import ModelTrainer
from neural_network.data_loader import create_data_loader

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = create_model(pretrained_path='neural_network/models/best_model.pth')

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
test_loader, _ = create_data_loader(
    data_dir='neural_network/data',
    batch_size=32,
    shuffle=False
)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
trainer = ModelTrainer(model)
predictions, probabilities = trainer.predict_batch(test_loader)

print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(predictions)}")
print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(predictions)}")
```

### 6.3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö —Å–≤–µ—á–∞—Ö

```python
import pandas as pd
import torch
from neural_network.model import create_model
from neural_network.data_loader import FlagPatternDataset

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = create_model(pretrained_path='neural_network/models/best_model.pth')
model.eval()

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ —Å–∫–∞–Ω–µ—Ä–∞)
df = scanner.get_candles_df('VKCO', 'TQBR', days_back=60)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ
temp_file = 'neural_network/data/temp_candles.csv'
df.to_csv(temp_file, index=False)

# –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
temp_dataset = FlagPatternDataset('neural_network/data', image_size=(224, 224))
# –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ annotations.csv –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–±

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—Ä—É—á–Ω—É—é
from neural_network.data_loader import FlagPatternDataset
image = temp_dataset._candles_to_image(df)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
image_batch = image.unsqueeze(0)
pred_class, probabilities = model.predict(image_batch)

class_names = ['–ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞', '–ë—ã—á–∏–π', '–ú–µ–¥–≤–µ–∂–∏–π']
print(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_names[pred_class.item()]}")
print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {probabilities[0][pred_class.item()]:.2%}")
```

---

## 7. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ —Å–∫–∞–Ω–µ—Ä–æ–º

### 7.1. –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∫–∞–Ω–µ—Ä–∞

–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–∫–∞–Ω–µ—Ä–∞:

```python
import os
from dotenv import load_dotenv
from scanners.combined_scanner import ComplexFlagScanner
from neural_network.model import create_model
from neural_network.data_loader import FlagPatternDataset
import torch

load_dotenv()

token = os.environ.get('TINKOFF_INVEST_TOKEN')
scanner = ComplexFlagScanner(token)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = create_model(pretrained_path='neural_network/models/best_model.pth')
model.eval()

# –°–∫–∞–Ω–∏—Ä—É–µ–º –∞–∫—Ü–∏—é
ticker = 'VKCO'
class_code = 'TQBR'
df = scanner.get_candles_df(ticker, class_code, days_back=60)

# –°–∫–∞–Ω–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω
patterns = scanner.analyze(df, timeframe='1h')

if patterns:
    pattern_info = patterns[0]
    scanner_label = 1 if 'BEARISH' not in pattern_info['pattern'] else 2
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
    dataset = FlagPatternDataset('neural_network/data')
    image = dataset._candles_to_image(df)
    image_batch = image.unsqueeze(0)
    
    pred_class, probabilities = model.predict(image_batch)
    nn_label = pred_class.item()
    
    print(f"–°–∫–∞–Ω–µ—Ä: {'–ë—ã—á–∏–π' if scanner_label == 1 else '–ú–µ–¥–≤–µ–∂–∏–π'}")
    print(f"–ù–µ–π—Ä–æ—Å–µ—Ç—å: {['–ù–µ—Ç', '–ë—ã—á–∏–π', '–ú–µ–¥–≤–µ–∂–∏–π'][nn_label]}")
    print(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏: {probabilities[0][nn_label]:.2%}")
    
    # –ï—Å–ª–∏ —Å–æ–≥–ª–∞—Å–Ω—ã
    if scanner_label == nn_label:
        print("‚úÖ –û–±–∞ –º–µ—Ç–æ–¥–∞ —Å–æ–≥–ª–∞—Å–Ω—ã - –ø–∞—Ç—Ç–µ—Ä–Ω –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω")
    else:
        print("‚ö†Ô∏è –ú–µ—Ç–æ–¥—ã –Ω–µ —Å–æ–≥–ª–∞—Å–Ω—ã - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞")
```

### 7.2. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥

–ú–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –∏ ML:

```python
def analyze_with_ml_validation(df, scanner, model, threshold=0.7):
    """
    –ê–Ω–∞–ª–∏–∑ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —á–µ—Ä–µ–∑ ML
    threshold - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
    """
    # –°–∫–∞–Ω–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω
    patterns = scanner.analyze(df, timeframe='1h')
    
    if not patterns:
        return []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å—é
    dataset = FlagPatternDataset('neural_network/data')
    image = dataset._candles_to_image(df)
    image_batch = image.unsqueeze(0)
    
    model.eval()
    pred_class, probabilities = model.predict(image_batch)
    
    max_prob = probabilities[0].max().item()
    predicted_label = pred_class.item()
    
    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º
    if max_prob < threshold:
        return []
    
    # –ï—Å–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≥–æ–≤–æ—Ä–∏—Ç "–Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞", –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º
    if predicted_label == 0:
        return []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
    pattern_info = patterns[0]
    scanner_label = 1 if 'BEARISH' not in pattern_info['pattern'] else 2
    
    if scanner_label == predicted_label:
        # –î–æ–±–∞–≤–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ML –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        pattern_info['ml_confidence'] = max_prob
        pattern_info['ml_validated'] = True
        return [pattern_info]
    
    return []

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
result = analyze_with_ml_validation(df, scanner, model, threshold=0.7)
if result:
    print(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω ML (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result[0]['ml_confidence']:.2%})")
```

---

## 8. –ß–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã

### Q: –°–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã—Ö –Ω—É–∂–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è?

**A:** –ú–∏–Ω–∏–º—É–º 100-200 –æ–±—Ä–∞–∑—Ü–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–Ω–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞, –±—ã—á–∏–π, –º–µ–¥–≤–µ–∂–∏–π). –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:
- –ù–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞: 300-500 –æ–±—Ä–∞–∑—Ü–æ–≤
- –ë—ã—á–∏–π: 200-300 –æ–±—Ä–∞–∑—Ü–æ–≤
- –ú–µ–¥–≤–µ–∂–∏–π: 200-300 –æ–±—Ä–∞–∑—Ü–æ–≤

### Q: –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏?

**A:**
1. **–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö** - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä
2. **–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤** - –ø—Ä–∏–º–µ—Ä–Ω–æ —Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
3. **–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞** - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–º–µ—á–∞–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
4. **–ë–æ–ª—å—à–µ —ç–ø–æ—Ö** - –æ–±—É—á–∞–π—Ç–µ –¥–æ–ª—å—à–µ (–Ω–æ —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º)
5. **–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö** - –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–ø–æ–≤–æ—Ä–æ—Ç, –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ)

### Q: –ß—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è?

**A:** –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è:
- Train accuracy —Ä–∞—Å—Ç–µ—Ç, Val accuracy –ø–∞–¥–∞–µ—Ç
- Val loss —Ä–∞—Å—Ç–µ—Ç –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —ç–ø–æ—Ö–∏

–†–µ—à–µ–Ω–∏—è:
- –£–≤–µ–ª–∏—á–∏—Ç—å dropout (—É–∂–µ 0.5)
- –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
- –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å early stopping
- –£–≤–µ–ª–∏—á–∏—Ç—å weight_decay

### Q: –ö–∞–∫ —É—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ?

**A:**
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU (CUDA)
2. –£–≤–µ–ª–∏—á—å—Ç–µ batch_size (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å)
3. –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 128x128 –≤–º–µ—Å—Ç–æ 224x224)
4. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ mixed precision training (FP16)

### Q: –ö–∞–∫ —á–∞—Å—Ç–æ –Ω—É–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å?

**A:** –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:
- –ü—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ 50-100 –Ω–æ–≤—ã—Ö —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
- –†–∞–∑ –≤ –Ω–µ–¥–µ–ª—é/–º–µ—Å—è—Ü (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
- –ü–æ—Å–ª–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ä—ã–Ω–∫–µ

### Q: –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –±–µ–∑ GPU?

**A:** –î–∞, –Ω–æ –æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–µ–µ. –î–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π CPU –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.

---

## üìä –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ workflow

```python
import os
from dotenv import load_dotenv
from scanners.combined_scanner import ComplexFlagScanner
from neural_network.annotator import PatternAnnotator
from neural_network.model import create_model
from neural_network.trainer import ModelTrainer
from neural_network.data_loader import create_data_loader
import torch

load_dotenv()

# 1. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
token = os.environ.get('TINKOFF_INVEST_TOKEN')
scanner = ComplexFlagScanner(token)
annotator = PatternAnnotator()

# 2. –†–ê–ó–ú–ï–¢–ö–ê –î–ê–ù–ù–´–• (–≤—ã–ø–æ–ª–Ω–∏—Ç—å –º–Ω–æ–≥–æ —Ä–∞–∑ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö)
tickers = ['VKCO', 'SBER', 'GAZP', 'LKOH', 'YNDX']
for ticker in tickers:
    df = scanner.get_candles_df(ticker, 'TQBR', days_back=60)
    patterns = scanner.analyze(df, timeframe='1h')
    if patterns:
        annotator.annotate_from_scanner(df, ticker, '1h', patterns[0])

annotator.print_statistics()

# 3. –û–ë–£–ß–ï–ù–ò–ï (–∫–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏—Ç—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = create_model(num_classes=3)
train_loader, val_loader = create_data_loader('neural_network/data', batch_size=16)
trainer = ModelTrainer(model, device=device)
trainer.train(train_loader, val_loader, epochs=50, save_dir='neural_network/models')

# 4. –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –î–õ–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô
model = create_model(pretrained_path='neural_network/models/best_model.pth')
model.eval()

df_new = scanner.get_candles_df('NEW_TICKER', 'TQBR', days_back=60)
# ... –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ...

# 5. –î–û–û–ë–£–ß–ï–ù–ò–ï (–ø–æ—Å–ª–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
model = create_model(pretrained_path='neural_network/models/best_model.pth')
new_loader, _ = create_data_loader('neural_network/data')
trainer = ModelTrainer(model)
trainer.fine_tune(new_loader, epochs=5, learning_rate=0.0001)
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

1. **–ù–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª–æ–≥–æ** - —Ä–∞–∑–º–µ—Ç—å—Ç–µ 50-100 –æ–±—Ä–∞–∑—Ü–æ–≤ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å
2. **–ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å** - —Ä–µ–≥—É–ª—è—Ä–Ω–æ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–æ–æ–±—É—á–∞–π—Ç–µ
3. **–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
4. **–ö–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –ø–æ–¥—Ö–æ–¥—ã** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏ –ø—Ä–∞–≤–∏–ª–∞, –∏ ML –≤–º–µ—Å—Ç–µ
5. **–í–µ–¥–∏—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ, –∫–∞–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã ML –Ω–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–µ/—Ö—É–∂–µ

---

**–£–¥–∞—á–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏! üöÄ**

